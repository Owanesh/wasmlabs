#!/usr/bin/env bun
import zlib from 'zlib';
import fs from 'fs';
import path from 'path';
import puppeteer from 'puppeteer';
import yargs from 'yargs';
import { hideBin } from 'yargs/helpers';

const argv = yargs(hideBin(process.argv))
    .option('url', { type: 'string', demandOption: true, description: 'The URL to trace' })
    .option('ssl-ignore-errors', { type: 'boolean', default: false, description: 'Ignore HTTPS certificate errors (pass to puppeteer.launch ignoreHTTPSErrors)' })
    .option('deep', { type: 'boolean', default: false, description: 'Enable deep tracing' })
    .option('timeout', { type: 'number', default: 9, description: 'Seconds to wait after page load before ending trace (useful to capture WASM/blob/workers)' })
    .option('categories', { type: 'string', description: 'Additional comma-separated tracing categories to append' })
    .option('out', { type: 'string', default: 'traces_output', description: 'Output folder base (a timestamp subfolder will be created)' })
    .option('chrome', { type: 'string', description: 'Path to Chromium/Chrome executable to use (overrides default)' })
    .help()
    .parseSync();

function makeChromiumArgs(): string[] {
    return [
        '--enable-automation',
        '--disable-background-timer-throttling',
        '--disable-renderer-backgrounding',
        '--disable-ipc-flooding-protection',
        '--enable-experimental-web-platform-features',
        '--enable-blink-features=IdleDetection,OffscreenCanvas',
        '--js-flags=--expose-gc',
        '--enable-precise-memory-info',
        '--enable-memory-info',
        '--enable-gpu-benchmarking',
        '--enable-logging=stderr',
        '--v=1',
        '--no-sandbox',
        // extra flags to surface deeper runtime/wasm/workers traces
        '--enable-webassembly',
        '--enable-experimental-web-platform-features',
        '--enable-blink-features=FeaturePolicyOldSyntax,OffscreenCanvas',
        '--js-flags=--trace-gc --trace-turbo --interpreted-frames-native-stack',
    ];
}

function buildCategories(deep: boolean): string {
    const base = [
        'devtools.timeline',
        'v8',
        'blink.user_timing',
        'blink.console',
        'net',
        'v8.wasm',
        'v8.execute',
        'disabled-by-default-devtools.timeline',
        'blob',
        'netlog',
        'native',
        'loading',
        'blink',
        'blink.resource',
        'blink.feature_usage',
        'blink.scheduler',
        'renderer.scheduler',
        'gpu',
        'toplevel',
        'blink.module_instantiation',
        'blink.net',
    ];

    if (deep) {
        base.push(
            'disabled-by-default-v8.cpu_profiler',
            'disabled-by-default-v8.runtime_stats',
            'disabled-by-default-v8.idle_deopt_stats',
            'disabled-by-default-memory-infra',
            'disabled-by-default-v8.heap_stats',
            'disabled-by-default-blink.worker',
            'disabled-by-default-v8.cpu_profiler.hires',
            'disabled-by-default-v8.wasm',
            'disabled-by-default-v8',
            'disabled-by-default-blink.module_instantiation',
            'disabled-by-default-memory.infra',
            'disabled-by-default-v8.console',
            'disabled-by-default-devtools.screenshot',
            'disabled-by-default-blink.scheduler',
            'disabled-by-default-blink.feature_usage',
            'disabled-by-default-blink.gc',
            'disabled-by-default-blink.console',
            'disabled-by-default-blink.resource_usage',
            'disabled-by-default-v8.runtime',
            'disabled-by-default-v8.gc',
            'disabled-by-default-embedded_worker',
            'disabled-by-default-blink.net',
            'disabled-by-default-blink.performance',
            'disabled-by-default-devtools.timeline.frame',
            'disabled-by-default-devtools.timeline.stack',
            'disabled-by-default-memory-infra.cpu_profiler',
        );
    }

    if ((argv as any).categories) {
        const extra = String((argv as any).categories).split(',').map((s) => s.trim()).filter(Boolean);
        base.push(...extra);
    }

    return Array.from(new Set(base)).join(',');
}

async function main() {
    const { url, deep, out } = argv as any;
    const baseOut = String(out).replace(/\/+$/, '');
    const ts = new Date().toISOString().replace(/[:.]/g, '-');
    const outDir = `${baseOut}/${ts}`;

    try { await Bun.mkdir(outDir, { recursive: true }); } catch { }
    try { fs.mkdirSync(outDir, { recursive: true }); } catch { }
    console.error('Output directory:', outDir);

    const jsonPath = `${outDir}/trace.json`;
    const gzPath = `${outDir}/trace.json.gz`;
    const reportPath = `${outDir}/report.md`;
    const filesDir = `${outDir}/files`;
    const turboDir = `${outDir}/turbo`;
    try { fs.mkdirSync(filesDir, { recursive: true }); } catch { }
    try { fs.mkdirSync(turboDir, { recursive: true }); } catch { }

    const originalCwd = process.cwd();

    console.info('Starting Bun-based headless tracing for:', url);
    console.info('Creating browser with args:', makeChromiumArgs().join(' '));

    const userChromium = '/Applications/Chromium.app/Contents/MacOS/Chromium';
    const chromeArg = (argv as any).chrome;
    let execPath: string | undefined = chromeArg || userChromium;

    let browser;
    try {
        const ignoreHTTPSErrors = Boolean((argv as any)['ssl-ignore-errors']);
        const args = makeChromiumArgs();
        const launchOpts: any = { headless: 'new', args, ignoreHTTPSErrors };
        if (execPath) launchOpts.executablePath = execPath;
        browser = await puppeteer.launch(launchOpts);
    } catch (launchErr) {
        console.error('puppeteer.launch failed:', launchErr);
        throw launchErr;
    }

    console.log('Browser launched');

    try {
        const page = await browser.newPage();
        console.log('New page created');
        if ((argv as any).ssl) { try { await page.setBypassCSP(true); } catch { } }
        const client = await page.target().createCDPSession();
        console.log('CDP session created');
        const categories = buildCategories(Boolean(deep));

        // expose a function to receive blob data from the page and save it
        await page.exposeFunction('__wasmlens_save_blob', async (meta: { suggestedName?: string, mime?: string }, b64: string) => {
            try {
                const buf = Buffer.from(b64, 'base64');
                const ext = meta && meta.mime ? meta.mime.split('/').pop() : 'blob';
                const name = meta && meta.suggestedName ? meta.suggestedName : `blob-${Date.now()}-${Math.random().toString(36).slice(2, 8)}.${ext}`;
                const outp = path.join(filesDir, name);
                await Bun.file(outp).write(buf);
                console.info('Saved page blob to', outp);
            } catch (e) { console.error('Failed saving blob', e); }
        });

        // inject script to intercept URL.createObjectURL and read blobs
        await page.evaluateOnNewDocument(() => {
            (function () {
                try {
                    const orig = URL.createObjectURL;
                    URL.createObjectURL = function (obj: any) {
                        try {
                            if (obj && typeof obj.arrayBuffer === 'function') {
                                obj.arrayBuffer().then((ab: ArrayBuffer) => {
                                    try {
                                        // convert to base64 in chunks
                                        const bytes = new Uint8Array(ab);
                                        let binary = '';
                                        const chunk = 0x8000;
                                        for (let i = 0; i < bytes.length; i += chunk) {
                                            binary += String.fromCharCode.apply(null, Array.from(bytes.subarray(i, i + chunk)));
                                        }
                                        const b64 = btoa(binary);
                                        // pass mime and no suggested name
                                        // @ts-ignore
                                        window.__wasmlens_save_blob({ mime: obj.type || 'application/octet-stream' }, b64);
                                    } catch (e) { /* ignore */ }
                                }).catch(() => { });
                            }
                        } catch (e) { }
                        return orig.apply(this, arguments as any);
                    };
                } catch (e) { }
            })();
        });

        // intercept network responses to capture .wasm and likely binary blobs
        page.on('response', async (res) => {
            try {
                const url = res.url();
                const headers = res.headers() || {};
                const ct = (headers['content-type'] || headers['Content-Type'] || '').toLowerCase();
                if (url.endsWith('.wasm') || ct.includes('application/wasm') || ct.includes('application/octet-stream') && url.includes('.wasm')) {
                    try {
                        const buf = await res.buffer();
                        const fname = path.basename(new URL(url).pathname) || `resource-${Date.now()}.wasm`;
                        const outp = path.join(filesDir, fname);
                        await Bun.file(outp).write(buf);
                        console.info('Saved wasm from', url, 'to', outp);
                    } catch (e) { console.error('save wasm failed', e); }
                }
            } catch (e) { /* ignore */ }
        });

        // streaming write for raw json (gzip will be created after the raw file is closed)
        const jsonWrite = fs.createWriteStream(jsonPath, { flags: 'w' });
        let jsonBytes = 0;
        let gzipBytes = 0;

        function oncePromise(emitter: any, event: string) {
            return new Promise<void>((resolve, reject) => {
                const onErr = (err: any) => { cleanup(); reject(err); };
                const onEv = () => { cleanup(); resolve(); };
                function cleanup() {
                    emitter.removeListener && emitter.removeListener('error', onErr);
                    emitter.removeListener && emitter.removeListener(event, onEv);
                }
                emitter.on && emitter.on('error', onErr);
                emitter.on && emitter.on(event, onEv);
            });
        }

        console.info('Starting tracing with categories:', categories);
        await client.send('Tracing.start', { transferMode: 'ReturnAsStream', categories, options: 'record-as-much-as-possible,enable-sampling' });
        console.log('Tracing.start called');

        // resolve local file paths
        let navigateUrl = url;
        try {
            const maybe = String(url);
            if (!/^https?:\/\//i.test(maybe) && !maybe.startsWith('file://')) {
                const abs = path.resolve(maybe);
                if (fs.existsSync(abs)) navigateUrl = 'file://' + abs;
            }
        } catch (e) { }

        console.log('Navigating to url...', navigateUrl);
        await page.goto(navigateUrl, { waitUntil: 'load', timeout: 60000 }).catch(() => null);

        const timeoutSec = Number((argv as any).timeout || 9);
        const waitMs = Math.max(0, Math.floor(timeoutSec * 1000));
        console.log(`Waiting ${waitMs}ms after load to capture activity`);
        await page.waitForTimeout(waitMs);

        console.log('Ending tracing...');
        // request tracing end and wait for Tracing.tracingComplete but with a timeout fallback
        try {
            await client.send('Tracing.end');
        } catch (e) {
            console.error('Tracing.end error', e);
        }

        const tracingComplete = await Promise.race([
            new Promise<any>((resolve) => {
                client.once('Tracing.tracingComplete', (event: any) => { console.error('Tracing.tracingComplete event'); resolve(event); });
            }),
            new Promise<any>((resolve) => setTimeout(() => resolve(null), 15000)),
        ]);

        if (!tracingComplete) {
            console.warn('No Tracing.tracingComplete received within timeout â€” proceeding to finalize files');
        }

        const handle = tracingComplete && tracingComplete.stream ? tracingComplete.stream : null;

        // read loop (only if we got a stream handle)
        if (handle) {
            let eof = false;
            while (!eof) {
                try {
                    const res = await client.send('IO.read', { handle, size: 64 * 1024 });
                    const dataBuf = res.base64Encoded ? Buffer.from(res.data, 'base64') : Buffer.from(res.data || '', 'utf8');
                    // write to raw json
                    if (!jsonWrite.write(dataBuf)) await oncePromise(jsonWrite, 'drain');
                    jsonBytes += dataBuf.length;
                    eof = res.eof === true;
                } catch (e) {
                    console.error('IO.read error', e);
                    break;
                }
            }
            try { await client.send('IO.close', { handle }); } catch (e) { /* ignore */ }
        } else {
            console.error('No trace stream handle, skipping IO.read loop');
        }

        try { await client.send('IO.close', { handle }); } catch { }

        // finish raw json then create gzip from the saved file (more reliable)
        jsonWrite.end();
        await oncePromise(jsonWrite, 'close');

        try {
            const src = fs.createReadStream(jsonPath);
            const gzWrite = fs.createWriteStream(gzPath, { flags: 'w' });
            const gzip = zlib.createGzip({ level: zlib.constants.Z_BEST_SPEED });
            src.pipe(gzip).pipe(gzWrite);
            // wait for either finish or close
            await Promise.race([oncePromise(gzWrite, 'finish'), oncePromise(gzWrite, 'close')]);
            try {
                const st = fs.statSync(gzPath);
                gzipBytes = (st as any).size || 0;
            } catch (e) {
                console.error('gzip stat failed', e);
            }
        } catch (e) {
            console.error('Failed creating gzip from json file', e);
        }

        console.info('Wrote bytes:', { jsonBytes, gzipBytes });
        console.log('Wrote raw trace and gzip');

        const reportLines = [
            '# Trace Report',
            `Generated: ${new Date().toISOString()}`,
            '',
            `Trace file: ${jsonPath}`,
            `Gzip file: ${gzPath}`,
            `Size (bytes): ${jsonBytes}`,
            `Gzip size (bytes): ${gzipBytes}`,
            `Categories: ${categories}`,
            `Timeout seconds: ${timeoutSec}`,
            '',
            'Notes:',
            '- This run produces a single raw `trace.json` intended for deep analysis of WASM, blob, workers, and XHR/network activity.',
            '- If you still miss events, increase `--timeout` and/or append more `--categories`.'
        ];

        try { await Bun.file(reportPath).write(reportLines.join('\n')); console.info('Wrote report'); } catch (e) { console.error('Report write failed', e); }

        // move any turbo-*.json files produced in cwd into turboDir
        try {
            const cwdFiles = fs.readdirSync(process.cwd());
            for (const f of cwdFiles) {
                if (/^turbo-.*\.json$/i.test(f) || /^turbo-.*\.cfg$/i.test(f)) {
                    const src = path.join(process.cwd(), f);
                    const dst = path.join(turboDir, f);
                    try { fs.renameSync(src, dst); } catch (e) { console.error('Move turbo failed', e); }
                }
            }
        } catch (e) { /* ignore */ }

    } finally {
        try { await browser.close(); } catch { }
        try { process.chdir(originalCwd); } catch { }
    }
}

main().catch((e) => { console.error(e); process.exit(2); });
