import re
import argparse
from collections import Counter
import csv
from pathlib import Path

# WASM opcodes set - using frozenset for better performance
WASM_OPCODES = frozenset([
    "unreachable", "nop", "block", "loop", "if", "else", "end",
    "br", "br_if", "br_table", "return", "call", "call_indirect",
    "local.get", "local.set", "local.tee", "global.get", "global.set",
    "i32.load", "i64.load", "f32.load", "f64.load",
    "i32.load8_s", "i32.load8_u", "i32.load16_s", "i32.load16_u",
    "i64.load8_s", "i64.load8_u", "i64.load16_s", "i64.load16_u", "i64.load32_s", "i64.load32_u",
    "i32.store", "i64.store", "f32.store", "f64.store",
    "i32.store8", "i32.store16", "i64.store8", "i64.store16", "i64.store32",
    "memory.size", "memory.grow", "memory.init", "data.drop", "memory.copy", "memory.fill",
    "table.init", "elem.drop", "table.copy", "table.grow", "table.size", "table.fill",
    "i32.const", "i64.const", "f32.const", "f64.const",
    "i32.eqz", "i32.eq", "i32.ne", "i32.lt_s", "i32.lt_u", "i32.gt_s", "i32.gt_u", "i32.le_s", "i32.le_u", "i32.ge_s", "i32.ge_u",
    "i32.clz", "i32.ctz", "i32.popcnt", "i32.add", "i32.sub", "i32.mul", "i32.div_s", "i32.div_u", "i32.rem_s", "i32.rem_u",
    "i32.and", "i32.or", "i32.xor", "i32.shl", "i32.shr_s", "i32.shr_u", "i32.rotl", "i32.rotr",
    "i64.eqz", "i64.eq", "i64.ne", "i64.lt_s", "i64.lt_u", "i64.gt_s", "i64.gt_u", "i64.le_s", "i64.le_u", "i64.ge_s", "i64.ge_u",
    "i64.clz", "i64.ctz", "i64.popcnt", "i64.add", "i64.sub", "i64.mul", "i64.div_s", "i64.div_u", "i64.rem_s", "i64.rem_u",
    "i64.and", "i64.or", "i64.xor", "i64.shl", "i64.shr_s", "i64.shr_u", "i64.rotl", "i64.rotr",
    "f32.eq", "f32.ne", "f32.lt", "f32.gt", "f32.le", "f32.ge", "f32.abs", "f32.neg", "f32.ceil", "f32.floor", "f32.trunc", "f32.nearest", "f32.sqrt", "f32.add", "f32.sub", "f32.mul", "f32.div", "f32.min", "f32.max", "f32.copysign",
    "f64.eq", "f64.ne", "f64.lt", "f64.gt", "f64.le", "f64.ge", "f64.abs", "f64.neg", "f64.ceil", "f64.floor", "f64.trunc", "f64.nearest", "f64.sqrt", "f64.add", "f64.sub", "f64.mul", "f64.div", "f64.min", "f64.max", "f64.copysign",
    "i32.wrap_i64", "i32.trunc_f32_s", "i32.trunc_f32_u", "i32.trunc_f64_s", "i32.trunc_f64_u",
    "i64.extend_i32_s", "i64.extend_i32_u", "i64.trunc_f32_s", "i64.trunc_f32_u", "i64.trunc_f64_s", "i64.trunc_f64_u",
    "f32.convert_i32_s", "f32.convert_i32_u", "f32.convert_i64_s", "f32.convert_i64_u", "f32.demote_f64",
    "f64.convert_i32_s", "f64.convert_i32_u", "f64.convert_i64_s", "f64.convert_i64_u", "f64.promote_f32",
    "i32.reinterpret_f32", "i64.reinterpret_f64", "f32.reinterpret_i32", "f64.reinterpret_i64",
    "ref.null", "ref.is_null", "ref.func", "try", "catch", "throw", "rethrow", "delegate", "catch_all",
    "return_call", "return_call_indirect", "struct.new", "struct.new_default", "struct.get", "struct.set",
    "array.new", "array.new_default", "array.get", "array.set", "array.len"
])

# Compiled regex pattern
OPCODE_PATTERN = re.compile(r"\b[a-z][a-z0-9_.]*\b")

def extract_opcodes(text):
    """Extract WASM opcodes from text and return a Counter."""
    tokens = OPCODE_PATTERN.findall(text)
    return Counter(token for token in tokens if token in WASM_OPCODES)

def create_detailed_csv(file_data, all_opcodes, output_file):
    """Create a detailed CSV with per-file opcode counts."""
    with open(output_file, "w", newline="", encoding="utf-8") as csvfile:
        sorted_opcodes = sorted(all_opcodes)
        header = ["filename"] + sorted_opcodes
        writer = csv.writer(csvfile)
        writer.writerow(header)
        
        for filename, counter in sorted(file_data.items()):
            row = [filename]
            for opcode in sorted_opcodes:
                row.append(counter.get(opcode, 0))
            writer.writerow(row)

def main():
    parser = argparse.ArgumentParser(description='Analyze WASM opcode usage in .wat files')
    parser.add_argument('input_folder', help='Input folder containing .wat files')
    parser.add_argument('output_folder', help='Output folder for reports')
    
    args = parser.parse_args()
    
    input_dir = Path(args.input_folder)
    output_dir = Path(args.output_folder)
    
    # Validate input directory
    if not input_dir.exists():
        print(f"Error: Input folder '{input_dir}' does not exist!")
        return
    
    # Create output directory
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Find all .wat files
    wat_files = list(input_dir.glob("*.wat"))
    
    if not wat_files:
        print(f"No .wat files found in '{input_dir}'")
        return
    
    print(f"Input folder: {input_dir}")
    print(f"Output folder: {output_dir}")
    print(f"Found {len(wat_files)} .wat files")
    print("-" * 50)
    
    file_data = {}
    global_counter = Counter()
    
    # Process each file
    for wat_file in wat_files:
        try:
            text = wat_file.read_text(encoding="utf-8")
            file_counter = extract_opcodes(text)
            
            file_data[wat_file.name] = file_counter
            global_counter.update(file_counter)
            
            total_opcodes = sum(file_counter.values())
            unique_opcodes = len(file_counter)
            print(f"{wat_file.name:30s} | {total_opcodes:>6d} opcodes | {unique_opcodes:>3d} unique")
            
        except Exception as e:
            print(f"Error processing {wat_file}: {e}")
            continue
    
    print("-" * 50)
    
    # Generate detailed CSV
    detailed_csv = output_dir / "detailed_opcode_analysis.csv"
    all_opcodes = set(global_counter.keys())
    create_detailed_csv(file_data, all_opcodes, detailed_csv)
    
    print(f"✓ Detailed CSV: {detailed_csv}")
    print(f"✓ Files processed: {len(file_data)}")
    print(f"✓ Total opcodes: {sum(global_counter.values()):,}")
    print(f"✓ Unique opcodes: {len(global_counter)}")

if __name__ == "__main__":
    main()